import os
import requests
import streamlit as st
from openai import OpenAI
from requests.adapters import HTTPAdapter, Retry

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚¦ã‚§ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰åˆ†æ",
    page_icon="ğŸŒ",
    layout="wide",
)

from utils.auth import check_authentication, show_logout_button

# èªè¨¼ãƒã‚§ãƒƒã‚¯
check_authentication()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
show_logout_button()

# OpenAI API ã‚­ãƒ¼ã®è¨­å®š
client = OpenAI(api_key=st.secrets["openai_api_key"])


def fetch_web_content(url: str) -> str:
    # ãƒªãƒˆãƒ©ã‚¤ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã‚’å«ã‚€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    session = requests.Session()
    retries = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[500, 502, 503, 504]
    )
    session.mount("http://", HTTPAdapter(max_retries=retries))
    session.mount("https://", HTTPAdapter(max_retries=retries))

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }

    response = session.get(url, headers=headers, timeout=30)
    response.raise_for_status()
    return response.text

def chunk_text(text: str, max_chars: int = 3000):
    chunks = []
    start = 0
    while start < len(text):
        end = start + max_chars
        chunks.append(text[start:end])
        start = end
    return chunks

def summarize_text(text_chunk: str, prompt_file_path: str) -> str:
    with open(prompt_file_path, "r", encoding="utf-8") as f:
        prompt_template = f.read()

    prompt = prompt_template.format(text_chunk)

    response = client.chat.completions.create(model=st.secrets["openai_model"],
    messages=[
        {"role": "system", "content": "You are a highly skilled financial analyst."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.5,
    max_tokens=3000)
    return response.choices[0].message.content

def summarize_long_text(text: str, prompt_file_path: str) -> str:
    chunks = chunk_text(text, max_chars=3000)
    partial_summaries = []

    for chunk in chunks:
        summary = summarize_text(chunk, prompt_file_path)
        partial_summaries.append(summary)

    combined_summary_text = "\n".join(partial_summaries)
    return summarize_text(combined_summary_text, prompt_file_path)

def main():
    st.title("ã‚¦ã‚§ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰åˆ†æ")

    web_url = st.text_input("ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "")

    if st.button("è¦ç´„ã‚’å®Ÿè¡Œ"):
        if not web_url.strip():
            st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        # æ—¢å­˜ã®è¦ç´„çµæœã‚’ã‚¯ãƒªã‚¢
        st.session_state["summary_output"] = None

        with st.spinner("ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦ã„ã¾ã™..."):
            try:
                web_content = fetch_web_content(web_url.strip())
            except requests.exceptions.RequestException as e:
                st.error(f"ã‚¦ã‚§ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                return

        if not web_content.strip():
            st.error("ã‚¦ã‚§ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        with st.spinner("è¦ç´„ã—ã¦ã„ã¾ã™..."):
            summary_output = summarize_long_text(web_content, "prompts/url_summary.txt")
            st.session_state["summary_output"] = summary_output

    # è¦ç´„çµæœãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¡¨ç¤º
    if "summary_output" in st.session_state and st.session_state["summary_output"]:
        st.subheader("è¦ç´„çµæœ")
        st.write(st.session_state["summary_output"])

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.download_button(
            label="è¦ç´„ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=st.session_state["summary_output"],
            file_name="summary.txt",
            mime="text/plain"
        )

if __name__ == "__main__":
    main()
