import os
import requests
import streamlit as st
from openai import OpenAI
from requests.adapters import HTTPAdapter, Retry
from bs4 import BeautifulSoup
from gtts import gTTS
import io
import markdown

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚¦ã‚§ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰åˆ†æ",
    page_icon="ğŸŒ",
    layout="wide",
)

from utils.auth import check_authentication, show_logout_button

# èªè¨¼ãƒã‚§ãƒƒã‚¯
check_authentication()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
show_logout_button()

# OpenAI API ã‚­ãƒ¼ã®è¨­å®š
client = OpenAI(api_key=st.secrets["openai_api_key"])


def fetch_web_content(url: str) -> str:
    response = requests.get(url)
    response.raise_for_status()  # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯

    # HTMLã‚’å–å¾—
    return response.content.decode('utf-8')

def chunk_text(text: str, max_chars: int = 3000):
    chunks = []
    start = 0
    while start < len(text):
        end = start + max_chars
        chunks.append(text[start:end])
        start = end
    return chunks

def summarize_text(text_chunk: str, prompt_file_path: str) -> str:
    with open(prompt_file_path, "r", encoding="utf-8") as f:
        prompt_template = f.read()

    prompt = prompt_template.format(text_chunk)

    response = client.chat.completions.create(model=st.secrets["openai_model"],
    messages=[
        {"role": "system", "content": "You are a highly skilled financial analyst."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.5,
    max_tokens=3000)
    return response.choices[0].message.content

def summarize_long_text(text: str, prompt_file_path: str) -> str:
    chunks = chunk_text(text, max_chars=3000)
    partial_summaries = []

    for chunk in chunks:
        summary = summarize_text(chunk, prompt_file_path)
        partial_summaries.append(summary)

    combined_summary_text = "\n".join(partial_summaries)
    return summarize_text(combined_summary_text, prompt_file_path)

# OpenAI APIã‚’ä½¿ç”¨ã—ã¦æœ¬æ–‡ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
def extract_main_content(html: str, prompt_file_path: str) -> str:
    with open(prompt_file_path, "r", encoding="utf-8") as f:
        prompt_template = f.read()

    prompt = prompt_template.format(html=html)

    response = client.chat.completions.create(model=st.secrets["openai_model"],
    messages=[
        {"role": "system", "content": "You are a highly skilled web content extractor."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.5,
    max_tokens=3000)
    return response.choices[0].message.content

def main():
    st.title("ã‚¦ã‚§ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰åˆ†æ")

    web_url = st.text_input("ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "")

    if st.button("è¦ç´„ã‚’å®Ÿè¡Œ"):
        if not web_url.strip():
            st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        # æ—¢å­˜ã®è¦ç´„çµæœã‚’ã‚¯ãƒªã‚¢
        st.session_state["summary_output"] = None

        with st.spinner("ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦ã„ã¾ã™..."):
            try:
                web_content = fetch_web_content(web_url.strip())
            except requests.exceptions.RequestException as e:
                st.error(f"ã‚¦ã‚§ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                return

        if not web_content.strip():
            st.error("ã‚¦ã‚§ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        with st.spinner("æœ¬æ–‡ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™..."):
            main_content = extract_main_content(web_content, "prompts/extract_main_content.txt")

        with st.spinner("è¦ç´„ã—ã¦ã„ã¾ã™..."):
            summary_output = summarize_long_text(main_content, "prompts/url_summary.txt")
            st.session_state["summary_output"] = summary_output

    # è¦ç´„çµæœãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¡¨ç¤º
    if "summary_output" in st.session_state and st.session_state["summary_output"]:
        st.subheader("è¦ç´„çµæœ")
        st.write(st.session_state["summary_output"])

        # Markdownã‚’ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
        html = markdown.markdown(st.session_state["summary_output"])
        soup = BeautifulSoup(html, "html.parser")
        plain_text_summary = soup.get_text()

        # éŸ³å£°ã§èª­ã¿ä¸Šã’ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ 
        tts = gTTS(plain_text_summary, lang='ja')
        tts.save("summary.mp3")

        audio_file = open("summary.mp3", "rb")
        audio_bytes = audio_file.read()

        st.audio(audio_bytes, format="audio/mp3")

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.download_button(
            label="è¦ç´„ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆéŸ³å£°å½¢å¼ï¼‰",
            data=audio_bytes,
            file_name="summary.mp3",
            mime="audio/mp3",
        )

if __name__ == "__main__":
    main()
